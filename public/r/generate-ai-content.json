{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "generate-ai-content",
  "type": "registry:item",
  "description": "Generate content using AI models with the Vercel AI SDK",
  "dependencies": [
    "ai"
  ],
  "files": [
    {
      "path": "steps/generate-ai-content.ts",
      "content": "import { generateText } from \"ai\"\nimport { FatalError } from \"workflow\"\n\ninterface GenerateAIContentParams {\n  prompt: string\n  model?: string\n  maxTokens?: number\n  temperature?: number\n}\n\n/**\n * Generate AI content using Vercel AI SDK with automatic retry logic.\n *\n * This step uses the Vercel AI Gateway by default, which supports multiple\n * providers without requiring individual API keys.\n *\n * @param prompt - The prompt to send to the AI model\n * @param model - Model to use (default: 'openai/gpt-4-turbo')\n * @param maxTokens - Maximum tokens in response\n * @param temperature - Creativity level (0-2)\n * @returns Generated text content\n */\nexport async function generateAIContent({\n  prompt,\n  model = \"openai/gpt-4-turbo\",\n  maxTokens = 500,\n  temperature = 0.7,\n}: GenerateAIContentParams) {\n  \"use step\"\n\n  if (!prompt || prompt.trim().length === 0) {\n    throw new FatalError(\"Prompt cannot be empty\")\n  }\n\n  try {\n    const { text } = await generateText({\n      model,\n      prompt,\n      maxTokens,\n      temperature,\n    })\n\n    return {\n      text,\n      model,\n      tokensUsed: text.length, // Approximate\n    }\n  } catch (error: any) {\n    // Check for fatal errors like invalid model\n    if (error.message?.includes(\"model not found\") || error.message?.includes(\"invalid model\")) {\n      throw new FatalError(`Invalid model: ${model}`)\n    }\n\n    // Let rate limits and transient errors retry\n    throw error\n  }\n}\n",
      "type": "registry:file",
      "target": "steps/generate-ai-content.ts"
    }
  ]
}